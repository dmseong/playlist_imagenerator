import streamlit as st
import requests
import spotipy
from spotipy.oauth2 import SpotifyClientCredentials
import difflib
import librosa
import numpy as np
from dotenv import load_dotenv
import os
import tempfile

load_dotenv()

st.markdown("""
<style>
.tooltip {
    position: relative;
    display: inline-block;
    cursor: help;
}

.tooltip .tooltiptext {
    visibility: hidden;
    width: 300px;
    background-color: black;
    color: white;
    text-align: center;
    border-radius: 7px;
    padding: 9px;
    position: absolute;
    z-index: 1;
    bottom: 125%; /* ìœ„ìª½ìœ¼ë¡œ ë°°ì¹˜ */
    left: 50%;
    transform: translateX(-50%);
    opacity: 0;
    transition: opacity 0.3s;
}

.tooltip:hover .tooltiptext {
    visibility: visible;
    opacity: 1;
}
</style>""", unsafe_allow_html=True)

# ë…¸ë˜ ì„ íƒ state ì´ˆê¸°í™”
if "songs" not in st.session_state:
    st.session_state.songs = []

if "selected_songs" not in st.session_state:
    st.session_state.selected_songs = []

if "past_selected_songs" not in st.session_state:
    st.session_state.past_selected_songs = []

if "searched" not in st.session_state:
    st.session_state.searched = False

# Hugging Face API ì„¤ì •(Stable Diffusion)
API_URL = "https://router.huggingface.co/hf-inference/models/stabilityai/stable-diffusion-3.5-large"
HEADERS = {"Authorization": f"Bearer {os.getenv('HUGGINGFACE_API_KEY')}"}

# Spotify API ì„¤ì •
SPOTIPY_CLIENT_ID = os.getenv("SPOTIPY_CLIENT_ID")
SPOTIPY_CLIENT_SECRET = os.getenv("SPOTIPY_CLIENT_SECRET")

auth_manager = SpotifyClientCredentials(client_id=SPOTIPY_CLIENT_ID, client_secret=SPOTIPY_CLIENT_SECRET)
sp = spotipy.Spotify(auth_manager=auth_manager)

def get_deezer_preview_url(song_name, artist_name):
    """Deezer APIë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ë…¸ë˜ì˜ ë¯¸ë¦¬ ë“£ê¸° URLì„ ê°€ì ¸ì˜´"""
    search_url = f"https://api.deezer.com/search?q={song_name} {artist_name}"
    
    # API ìš”ì²­
    response = requests.get(search_url)
    
    # ìƒíƒœ ì½”ë“œê°€ 200ì´ë©´ ì •ìƒì ì¸ ì‘ë‹µ
    if response.status_code == 200:
        data = response.json()
        
        # 'data' í‚¤ê°€ ì¡´ì¬í•˜ê³ , ê·¸ ì•ˆì— ê³¡ì´ ìˆë‹¤ë©´
        if "data" in data and len(data["data"]) > 0:
            # ì œëª©ê³¼ ì•„í‹°ìŠ¤íŠ¸ì˜ ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´ fuzzy matching ì‚¬ìš©
            best_match = None
            highest_ratio = 0
            
            for track in data["data"]:
                # ì œëª©ê³¼ ì•„í‹°ìŠ¤íŠ¸ì˜ ë§¤ì¹­ ë¹„ìœ¨ ê³„ì‚°
                title_ratio = difflib.SequenceMatcher(None, track["title"].lower(), song_name.lower()).ratio()
                artist_ratio = difflib.SequenceMatcher(None, track["artist"]["name"].lower(), artist_name.lower()).ratio()
                
                # ë‘ ë¹„ìœ¨ì„ í•©ì‚°í•˜ì—¬ ë” ë†’ì€ ë¹„ìœ¨ì„ ì°¾ìŒ
                total_ratio = title_ratio + artist_ratio
                
                # ê°€ì¥ ë†’ì€ ë¹„ìœ¨ì„ ê°€ì§„ íŠ¸ë™ ì„ íƒ
                if total_ratio > highest_ratio:
                    highest_ratio = total_ratio
                    best_match = track
            
            if best_match:
                return best_match["preview"]
    
    return None  # Deezerì—ì„œ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš°

# ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë° librosaë¡œ íŠ¹ì§• ì¶”ì¶œ
def extract_audio_features(url):
    """Deezer MP3ë¥¼ librosaë¡œ ì§ì ‘ ë¶„ì„"""
    response = requests.get(url, stream=True)
    if response.status_code != 200:
        raise ValueError("ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨!")

    # ì„ì‹œ íŒŒì¼ì— MP3 ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
        tmp_filename = tmp_file.name  # íŒŒì¼ ê²½ë¡œ ì €ì¥
        tmp_file.write(response.content)

    try:
        tmp_file.close()

        # librosaë¡œ MP3 íŒŒì¼ ë¡œë“œ
        audio_data, sr = librosa.load(tmp_filename, sr=None)

        # ì˜¤ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ
        tempo, _ = librosa.beat.beat_track(y=audio_data, sr=sr)
        if tempo > 170:
            tempo /= 2 
        spectral_centroid = librosa.feature.spectral_centroid(y=audio_data, sr=sr)
        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio_data, sr=sr)

        features = {
            'tempo': tempo,
            'spectral_centroid': np.mean(spectral_centroid),
            'spectral_bandwidth': np.mean(spectral_bandwidth)
        }
        return features

    finally:
        # íŒŒì¼ ì‚­ì œ
        os.remove(tmp_filename)

# ì¢…í•©ì ì¸ ë¶„ìœ„ê¸° ê³„ì‚°
def aggregate_features(features_list):
    if not features_list:
        return None
    avg_features = {key: np.mean([f[key] for f in features_list]) for key in features_list[0]}
    st.write("### í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼")
    st.markdown(f"ğŸµ í‰ê·  í…œí¬: {avg_features['tempo']:.2f} BPM")
    st.markdown(f"""
                <p class="tooltip">ğŸ¶ í‰ê·  ìŠ¤í™íŠ¸ëŸ´ ì„¼íŠ¸ë¡œì´ë“œ: {avg_features['spectral_centroid']:.2f}
                    <span class="tooltiptext">ì´ ê°’ì´ ë†’ì„ìˆ˜ë¡ ìŒìƒ‰ì´ ë°ìŠµë‹ˆë‹¤.</span>
                </p>
                """, unsafe_allow_html=True)
    st.markdown(f"""
                <p class="tooltip">ğŸ¸ í‰ê·  ìŠ¤í™íŠ¸ëŸ´ ë°´ë“œìœ„ë“œ: {avg_features['spectral_bandwidth']:.2f}
                    <span class="tooltiptext">ì´ ê°’ì´ í´ìˆ˜ë¡ ìŒì•…ì˜ ë‹¤ì´ë‚´ë¯¹ ë ˆì¸ì§€ê°€ ë„“ìŠµë‹ˆë‹¤.</span>
                </p>
                """, unsafe_allow_html=True)
    return avg_features

# Stable Diffusion ì´ë¯¸ì§€ ìƒì„±
def generate_playlist_image(features, style, color):
    # ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸
    style_prompt = {
        "Color": "Express the mood of the music using only gradients of different colors. You must not draw any objects.",
        "Chracter": "Please create a cover with a Japanese anime style character that matches the mood of the music.",
        "Landscape": "Create a cover that reflects the overall mood of the music in the form of a landscape.",
        "Abstract": "Create an abstract cover that captures the essence of the music."
    }.get(style, "Color")

    color_prompt = f" Use a gradient effect based on the {color}, and express the emotional mood of the music through this gradient."

    prompt = f"A playlist cover reflecting the overall musical vibe:"
    
    # ğŸµ ìŒì•…ì˜ í…œí¬(ì†ë„) ë¶„ì„
    if features['tempo'] > 160:
        prompt += " A very fast and high-energy track, often found in intense rock or electronic music."  # ë§¤ìš° ë¹ ë¥´ê³  ì—ë„ˆì œí‹±í•œ ìŒì•… (ê°•ë ¬í•œ ë¡, ë¹ ë¥¸ ì „ì ìŒì•…)
    elif features['tempo'] > 130:
        prompt += " A fast and energetic rhythm, commonly heard in rock, punk, and dance music."  # ë¹ ë¥´ê³  ì—ë„ˆì§€ ë„˜ì¹˜ëŠ” ë¦¬ë“¬ (ë¡, í‘í¬, ëŒ„ìŠ¤ ìŒì•…)
    elif features['tempo'] > 100:
        prompt += " A moderately fast tempo, giving a vibrant and lively feel."  # ì ë‹¹íˆ ë¹ ë¥¸ í…œí¬ë¡œ ìƒë™ê° ìˆëŠ” ë¶„ìœ„ê¸°
    elif features['tempo'] > 70:
        prompt += " A balanced rhythm with a relaxed yet engaging pace."  # ê· í˜• ì¡íŒ ë¦¬ë“¬, í¸ì•ˆí•˜ë©´ì„œë„ ëª°ì…ê° ìˆëŠ” í…œí¬
    else:
        prompt += " A slow and soothing track with a calm and peaceful atmosphere."  # ëŠë¦¬ê³  ì°¨ë¶„í•œ ìŒì•… (ì”ì”í•œ ë°œë¼ë“œ, ì–´ì¿ ìŠ¤í‹±)

    # ğŸ¸ ìŒì•…ì˜ ìŒìƒ‰(ë°ê¸°) ë¶„ì„ (ìŠ¤í™íŠ¸ëŸ´ ì„¼íŠ¸ë¡œì´ë“œ)
    if features['spectral_centroid'] > 5500:
        prompt += " A bright and sharp sound, often associated with high-energy rock and metal."  # ë°ê³  ë‚ ì¹´ë¡œìš´ ì‚¬ìš´ë“œ (ì—ë„ˆì§€ ë„˜ì¹˜ëŠ” ë¡, ë©”íƒˆ)
    elif features['spectral_centroid'] > 4000:
        prompt += " A slightly bright yet warm tone, commonly found in pop rock and alternative music."  # ë‹¤ì†Œ ë°ìœ¼ë©´ì„œë„ ë”°ëœ»í•œ í†¤ (íŒ ë¡, ì–¼í„°ë„ˆí‹°ë¸Œ)
    elif features['spectral_centroid'] > 2500:
        prompt += " A well-balanced sound with a mix of warmth and clarity."  # ë”°ëœ»í•¨ê³¼ ëª…ë£Œí•¨ì´ ì¡°í™”ëœ ì‚¬ìš´ë“œ
    else:
        prompt += " A deep and mellow tone, often associated with acoustic and jazz music."  # ë¶€ë“œëŸ½ê³  ê¹Šì€ í†¤ (ì–´ì¿ ìŠ¤í‹±, ì¬ì¦ˆ)

    # ğŸ¶ ìŒì•…ì˜ ì‚¬ìš´ë“œ ë‹¤ì´ë‚´ë¯¹(í­) ë¶„ì„ (ìŠ¤í™íŠ¸ëŸ´ ë°´ë“œìœ„ë“œ)
    if features['spectral_bandwidth'] > 3000:
        prompt += " A highly dynamic and expressive sound with a wide frequency range."  # ë§¤ìš° ë‹¤ì´ë‚´ë¯¹í•˜ê³  í‘œí˜„ë ¥ì´ ê°•í•œ ì‚¬ìš´ë“œ
    elif features['spectral_bandwidth'] > 2000:
        prompt += " A vibrant and energetic texture, often found in rock and upbeat tracks."  # ìƒë™ê° ìˆê³  ì—ë„ˆì§€ ë„˜ì¹˜ëŠ” ì§ˆê° (ë¡, ì—…í…œí¬ ìŒì•…)
    elif features['spectral_bandwidth'] > 1200:
        prompt += " A smooth and clear sound with a mix of mellow and bright elements."  # ë¶€ë“œëŸ¬ìš°ë©´ì„œë„ ì„ ëª…í•œ ì‚¬ìš´ë“œ (ë°ì€ ìš”ì†Œì™€ ë¶€ë“œëŸ¬ìš´ ìš”ì†Œê°€ í˜¼í•©)
    else:
        prompt += " A soft and warm sound with subtle variations, ideal for calm and acoustic music."  # ë¶€ë“œëŸ½ê³  ë”°ëœ»í•œ ì‚¬ìš´ë“œ, ì°¨ë¶„í•œ ìŒì•…ì— ì í•© (ì–´ì¿ ìŠ¤í‹±, í¬í¬)
    
    prompt += f" {style_prompt} {color_prompt}"

    payload = {"inputs": prompt}
    response = requests.post(API_URL, headers=HEADERS, json=payload)
    
    if response.status_code == 200:
        st.write(prompt)
        return response.content
    else:
        st.error("ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨!")
        return None

def search_songs(query):
    """Spotifyì—ì„œ ë…¸ë˜ ê²€ìƒ‰ í›„ Deezerì—ì„œ ë¯¸ë¦¬ ë“£ê¸° URL ê°€ì ¸ì˜¤ê¸°"""
    results = sp.search(q=query, limit=6, type='track')
    songs = []

    for track in results['tracks']['items']:
        song_name = track['name']
        artist_name = track['artists'][0]['name']

        # ê²€ìƒ‰ ê²°ê³¼ ì¤‘ë³µ ì œì™¸
        if any(s['name'] == song_name and s['artist'] == artist_name for s in songs):
            print(f"\n\nSkipping duplicate: {song_name} - {artist_name}")
            continue

        # Deezerì—ì„œ ë¯¸ë¦¬ ë“£ê¸° URL ê°€ì ¸ì˜¤ê¸° (ì œëª©&ì•„í‹°ìŠ¤íŠ¸ ë¹„êµ)
        deezer_data = get_deezer_preview_url(song_name, artist_name)
        preview_url = deezer_data if deezer_data else None

        # ì•¨ë²” ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
        album_images = track['album'].get('images', [])
        image_url = album_images[0]['url'] if album_images else ""

        songs.append({
            "name": song_name,
            "artist": artist_name,
            "image": image_url,
            "deezer_preview_url": preview_url
        })
        
    return songs

st.title("ğŸµ Playlist imagenerator")
query = st.text_input("ì œëª© í˜¹ì€ ê°€ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

if st.button("ê²€ìƒ‰") and query:
    if st.session_state.searched:
        selected_song_data = [s for s in st.session_state.songs if f"{s['name']} - {s['artist']}" in st.session_state.selected_songs]
        st.session_state.past_selected_songs.append(selected_song_data)
        st.session_state.songs = search_songs(query)
    else:
        st.session_state.songs = search_songs(query)
        st.session_state.searched = True

# ê²€ìƒ‰ ê²°ê³¼ê°€ ë³€ê²½ë  ë•Œ, ê¸°ì¡´ ì„ íƒ ëª©ë¡ì„ í•„í„°ë§
available_songs = [f"{s['name']} - {s['artist']}" for s in st.session_state.songs]
valid_selected_songs = [s for s in st.session_state.selected_songs if s in available_songs]  # âœ… ìœ íš¨í•œ ê°’ë§Œ ìœ ì§€

def update_selected_songs():
    """ ì‚¬ìš©ìê°€ ì„ íƒí•œ ê³¡ì„ session_stateì— ë°˜ì˜ """
    # temp_selected_songsë¥¼ session_state.selected_songsì— ì—…ë°ì´íŠ¸
    st.session_state.selected_songs = st.session_state.temp_selected_songs
    
    # past_selected_songsë¥¼ í‰íƒ„í™”í•˜ì—¬ selected_songsì˜ 0ë²ˆì§¸ì— ì‚½ì…
    flattened_past_songs = [song for sublist in st.session_state.past_selected_songs for song in sublist]
    
    # past_selected_songsë¥¼ selected_songs ì•ì— ë¶™ì—¬ì¤Œ
    st.session_state.selected_songs = flattened_past_songs + st.session_state.selected_songs


# ğŸ”¥ ë…¸ë˜ ì„ íƒ UI (ìœ íš¨í•œ ê°’ë§Œ defaultë¡œ ì„¤ì •)
st.multiselect(
    "ë…¸ë˜ë¥¼ ì„ íƒí•˜ì„¸ìš”",
    options=available_songs,
    default=valid_selected_songs,  
    key="temp_selected_songs",
    on_change=update_selected_songs
)

# past_selected_songsë¥¼ í‰íƒ„í™”í•˜ê³ , selected_song_dataì™€ ê²°í•©
def get_selected_song_data():
    selected_song_data = [s for s in st.session_state.songs if f"{s['name']} - {s['artist']}" in st.session_state.selected_songs]
    flattened_past_songs = [song for sublist in st.session_state.past_selected_songs for song in sublist]
    selected_song_data = flattened_past_songs + selected_song_data # past_selected_songsë¥¼ ì•ì— ë¶™ì—¬ì„œ ê²°í•©
    return selected_song_data

# ì„ íƒí•œ ë…¸ë˜ë¥¼ ê°€ë¡œ ì •ë ¬ë¡œ í‘œì‹œ
if st.session_state.selected_songs:
    st.write("### ì„ íƒí•œ ë…¸ë˜")
    selected_song_data = get_selected_song_data()  
    
    # ì„ íƒëœ ë…¸ë˜ë“¤ì„ ì»¬ëŸ¼ì— ë§ê²Œ ì •ë ¬í•˜ì—¬ í‘œì‹œ
    cols = st.columns(len(selected_song_data))
    for idx, song in enumerate(selected_song_data):
        with cols[idx]:
            st.image(song['image'], width=150)
            st.write(f"**{song['name']}**")
            st.write(song['artist'])

cols = st.columns(2)  # ì—´ì„ ìƒì„±
style = cols[0].radio("**Illustrate Style**", ["Color", "Character", "Landscape", "Abstract"])  # ì²« ë²ˆì§¸ ì—´ì—ì„œ ë¼ë””ì˜¤ ë²„íŠ¼
color = cols[1].color_picker("**Overall color**", "#ff0000")  # ë‘ ë²ˆì§¸ ì—´ì—ì„œ ìƒ‰ìƒ ì„ íƒê¸°

if st.session_state.selected_songs and st.button("í‘œì§€ ìƒì„±"):
    with st.spinner("í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë¶„ì„ ì¤‘..."):
        selected_song_data = get_selected_song_data()  
        features_list = [extract_audio_features(s['deezer_preview_url']) for s in selected_song_data if s['deezer_preview_url']]
        valid_features = [f for f in features_list if f]
        aggregated_features = aggregate_features(valid_features) if valid_features else None
    if aggregated_features:
        with st.spinner("í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ í‘œì§€ ìƒì„± ì¤‘..."):
            image_url = generate_playlist_image(aggregated_features, style, color)
            if image_url:
                st.image(image_url, caption="ìƒì„±ëœ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ í‘œì§€", width=250)
            else:
                st.toast("ì´ë¯¸ì§€ URLì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.", icon="ğŸ˜¢")
    else:
        st.error("ì˜¤ë””ì˜¤ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")